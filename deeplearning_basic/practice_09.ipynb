{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1233, -0.7327,  0.9121, -0.0747],\n",
      "        [ 1.1119, -0.7013, -2.3540, -1.3027],\n",
      "        [ 0.7007,  0.9611, -0.4342,  0.3471]])\n",
      "tensor([1, 2])\n",
      "tensor([[ 1.1119, -0.7013, -2.3540, -1.3027],\n",
      "        [ 0.7007,  0.9611, -0.4342,  0.3471]])\n",
      "tensor([[-0.7327,  0.9121],\n",
      "        [-0.7013, -2.3540],\n",
      "        [ 0.9611, -0.4342]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "data1 = torch.randn(3,4)\n",
    "print(data1)\n",
    "indices = torch.tensor([1,2]) # 1,2번째 행,열을 가져옴\n",
    "print(indices)\n",
    "print(torch.index_select(data1, 0, indices)) # 0 축을 기준으로 1,2번째 행을 가져옴\n",
    "print(torch.index_select(data1, 1, indices)) # 1 축을 기준으로 1,2번째 열을 가져옴\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(5000,10) # 5000개의 데이터, 10개의 특징\n",
    "y = torch.zeros(5000,1) # 5000개의 데이터에 대한 예측값\n",
    "\n",
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "mini_batch_size = 256 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x.size(-1) # 10\n",
    "output_dim = y.size(-1) # 1\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 10),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(10, 8),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(8, 6),\n",
    "    nn.LeakyReLU(0.1),\n",
    "    nn.Linear(6, output_dim)\n",
    ")\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.3553e-16, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[-0.2679, -0.0344, -0.2605,  0.0918,  0.0302,  0.0214, -0.3016, -0.1171,\n",
      "         -0.2156,  0.0351],\n",
      "        [ 0.1124,  0.1762, -0.3135,  0.1598,  0.0177,  0.0204,  0.1546, -0.2700,\n",
      "          0.1810, -0.1491],\n",
      "        [ 0.0910,  0.0493,  0.0680,  0.3021, -0.0225, -0.2828, -0.1399, -0.0623,\n",
      "          0.2018,  0.2156],\n",
      "        [ 0.2562,  0.1169, -0.2756,  0.1799,  0.0894,  0.0494,  0.1497,  0.2411,\n",
      "         -0.0648,  0.2172],\n",
      "        [-0.0776, -0.2279, -0.2630,  0.0023, -0.0159,  0.2911, -0.0461, -0.1016,\n",
      "         -0.0783,  0.3055],\n",
      "        [-0.1738,  0.2886, -0.0949, -0.2071, -0.2162,  0.1225, -0.0041, -0.0071,\n",
      "         -0.2747,  0.1396],\n",
      "        [ 0.2406, -0.1152, -0.0742, -0.1968, -0.1110,  0.2823,  0.2306, -0.0756,\n",
      "         -0.0875,  0.0723],\n",
      "        [-0.2657,  0.1052, -0.1438, -0.3151, -0.2335, -0.2758,  0.1613, -0.2723,\n",
      "         -0.1265, -0.2902],\n",
      "        [ 0.1365, -0.1283, -0.2009, -0.1143, -0.0081, -0.2079,  0.2219, -0.2281,\n",
      "          0.1362,  0.0206],\n",
      "        [ 0.2242,  0.1771, -0.2937, -0.1524, -0.0146, -0.1462, -0.0214,  0.0733,\n",
      "          0.2454,  0.0456]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0337,  0.1817,  0.1992, -0.2970, -0.2246, -0.3021,  0.2874, -0.2135,\n",
      "         0.1705, -0.2632], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2129, -0.2328, -0.0939, -0.1557, -0.1176,  0.2610, -0.1532, -0.3098,\n",
      "         -0.0081,  0.1607],\n",
      "        [ 0.2260,  0.1695,  0.2463,  0.2330,  0.1608,  0.1048, -0.1246, -0.3053,\n",
      "         -0.3124, -0.2366],\n",
      "        [ 0.0768, -0.0791, -0.3019,  0.0674, -0.0486, -0.2625, -0.0502, -0.0407,\n",
      "         -0.1524,  0.0121],\n",
      "        [ 0.0471, -0.3150, -0.1197,  0.1518,  0.1106,  0.1592, -0.3095, -0.1120,\n",
      "          0.1635,  0.1987],\n",
      "        [-0.2318,  0.3021,  0.0717, -0.2969, -0.1542,  0.3137,  0.1468, -0.0786,\n",
      "         -0.2577,  0.2467],\n",
      "        [ 0.0164, -0.1129, -0.0567, -0.0746, -0.1129, -0.2370, -0.2110, -0.1732,\n",
      "         -0.0171, -0.2286],\n",
      "        [ 0.1552, -0.1768,  0.1830, -0.2395,  0.2848,  0.1678,  0.2705, -0.0547,\n",
      "          0.0702, -0.0419],\n",
      "        [ 0.1253,  0.1302,  0.0430, -0.0997,  0.1820,  0.0836,  0.0273, -0.3076,\n",
      "         -0.0402, -0.1941]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1222,  0.0857, -0.0170,  0.0059, -0.1678,  0.3143, -0.1581, -0.2052],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0818, -0.2933,  0.3228, -0.0330, -0.1217, -0.0228, -0.0453, -0.3481],\n",
      "        [-0.1282,  0.3128,  0.3324, -0.2677,  0.1012, -0.2489, -0.0214,  0.3355],\n",
      "        [ 0.3300,  0.2310,  0.0753, -0.2540, -0.2865,  0.2955,  0.2827, -0.0768],\n",
      "        [-0.3256,  0.2781, -0.2805,  0.3310, -0.3501,  0.2321, -0.1611, -0.2571],\n",
      "        [ 0.0068,  0.1068, -0.0870, -0.1876, -0.2138,  0.0907, -0.2434,  0.2175],\n",
      "        [-0.1981, -0.0066,  0.3034, -0.0790, -0.3104, -0.1148, -0.2912, -0.2366]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0816,  0.1959,  0.2152,  0.2206, -0.2590,  0.0719],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2596,  0.3324, -0.1596, -0.0836, -0.2247,  0.0463]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0055], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for index in range(nb_epochs):\n",
    "\n",
    "    indices = torch.randperm(x.size(0)) # 5000개의 데이터에 대한 인덱스를 랜덤하게 섞음\n",
    "    x_batch_list = torch.index_select(x, 0, index=indices)\n",
    "    y_batch_list = torch.index_select(y, 0, index=indices)\n",
    "    x_batch_list = x_batch_list.split(mini_batch_size, dim=0) # mini_batch 생성\n",
    "    y_batch_list = y_batch_list.split(mini_batch_size, dim=0) # mini_batch 생성\n",
    "    \n",
    "    for x_minibatch, y_minibatch in zip(x_batch_list, y_batch_list):\n",
    "        y_pred = model(x_minibatch)\n",
    "        loss = loss_fn(y_pred, y_minibatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
