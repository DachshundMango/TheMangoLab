{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다층 레이어 구현\n",
    "# input layer -> hidden layer -> output layer 순으로 구성\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 10)\n",
    "        self.linear2 = nn.Linear(10, 10) \n",
    "        self.linear3 = nn.Linear(10, 10)\n",
    "        self.linear4 = nn.Linear(10, output_dim) \n",
    "        self.activation = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden = self.activation(self.linear1(x))\n",
    "        hidden = self.activation(self.linear2(hidden))\n",
    "        hidden = self.activation(self.linear3(hidden))\n",
    "        y = self.linear4(hidden) # 마지막 출력에는 activation function을 사용하지 않음\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(4)\n",
    "y = torch.zeros(3)\n",
    "model = LinearRegressionModel(4, 3)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6.4008e-10, grad_fn=<MseLossBackward0>)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1745,  0.3462,  0.0218, -0.0936],\n",
      "        [-0.0153,  0.2503, -0.0496,  0.0696],\n",
      "        [-0.1459,  0.0704, -0.2363, -0.3638],\n",
      "        [ 0.4800,  0.3918,  0.1549, -0.2321],\n",
      "        [-0.0454, -0.2194, -0.1364,  0.0475],\n",
      "        [-0.4809,  0.0362, -0.0198,  0.1904],\n",
      "        [ 0.4787, -0.4818,  0.4565,  0.0256],\n",
      "        [-0.2231,  0.4883, -0.4384,  0.2023],\n",
      "        [ 0.3695,  0.3422, -0.1641, -0.2309],\n",
      "        [ 0.2564, -0.2759, -0.0363, -0.0125]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.4034, -0.4755,  0.4147,  0.2092, -0.3845,  0.3379,  0.1719, -0.1932,\n",
      "        -0.0182, -0.1498], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2184, -0.0227, -0.0215,  0.1802, -0.1862,  0.1847, -0.2704,  0.2748,\n",
      "          0.3102,  0.2107],\n",
      "        [-0.1935,  0.1494,  0.1637, -0.1262,  0.2294, -0.0867,  0.0662,  0.2949,\n",
      "         -0.1954,  0.0146],\n",
      "        [-0.2562,  0.1742, -0.0338, -0.1034, -0.1280, -0.2780,  0.2449,  0.1349,\n",
      "          0.0532,  0.2884],\n",
      "        [ 0.2086,  0.1590, -0.1388,  0.2943, -0.0541,  0.1989, -0.0793,  0.2527,\n",
      "         -0.0730, -0.1001],\n",
      "        [ 0.1997,  0.1543, -0.0061, -0.2643,  0.2848, -0.2885, -0.0936,  0.2530,\n",
      "         -0.1402,  0.2940],\n",
      "        [ 0.0551,  0.2581, -0.1636,  0.0792, -0.0849, -0.2607, -0.2733, -0.2699,\n",
      "         -0.0733, -0.1437],\n",
      "        [ 0.1614, -0.2366, -0.0698, -0.1050, -0.1427, -0.1629,  0.1641,  0.2443,\n",
      "         -0.1504, -0.1697],\n",
      "        [-0.1209, -0.0053,  0.0898,  0.1004,  0.1395, -0.1286, -0.0008, -0.0879,\n",
      "          0.0508, -0.0077],\n",
      "        [ 0.2654,  0.0978, -0.0925, -0.1518,  0.2569, -0.0672,  0.2090, -0.1054,\n",
      "         -0.2264,  0.2113],\n",
      "        [ 0.1342, -0.1201,  0.2774, -0.2422,  0.3031,  0.1765, -0.3047, -0.1248,\n",
      "         -0.1506,  0.2557]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1943,  0.1182, -0.1826, -0.2353,  0.0400, -0.2736, -0.2959,  0.1916,\n",
      "        -0.2844, -0.2633], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0760, -0.1819,  0.0744,  0.2361,  0.1409,  0.1257, -0.2216, -0.1503,\n",
      "          0.0803,  0.1102],\n",
      "        [ 0.2412,  0.2037,  0.3122,  0.1879,  0.2477, -0.2431, -0.0621,  0.0668,\n",
      "          0.2923,  0.3039],\n",
      "        [ 0.2099,  0.0400, -0.0990,  0.0172, -0.0937, -0.1096,  0.1236, -0.1171,\n",
      "          0.2798,  0.0314],\n",
      "        [ 0.0182,  0.1603, -0.0876, -0.0036, -0.1733,  0.1724,  0.0238,  0.1827,\n",
      "          0.1866, -0.2933],\n",
      "        [-0.0524, -0.0868, -0.0226,  0.1118,  0.1426, -0.1092, -0.1145, -0.1477,\n",
      "         -0.0197, -0.0260],\n",
      "        [-0.1789,  0.1376, -0.1761, -0.2768, -0.1909,  0.0534,  0.0393,  0.0505,\n",
      "         -0.1404, -0.1171],\n",
      "        [ 0.0623,  0.2261,  0.2003,  0.1199, -0.0364, -0.2244, -0.2579, -0.2270,\n",
      "         -0.2581, -0.1775],\n",
      "        [ 0.1164, -0.0766,  0.0089, -0.2330, -0.1973, -0.0567,  0.0396, -0.2262,\n",
      "          0.1121, -0.0284],\n",
      "        [-0.1124,  0.1998, -0.2624,  0.1900, -0.0887,  0.0367, -0.0489, -0.0846,\n",
      "          0.0558, -0.2525],\n",
      "        [-0.1472, -0.0267, -0.0535, -0.1830,  0.1609, -0.0628, -0.0789,  0.1250,\n",
      "          0.1418,  0.0194]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2547, -0.0561, -0.0143,  0.0167,  0.2467, -0.1511,  0.1779, -0.0227,\n",
      "         0.0488,  0.1150], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0679,  0.2214, -0.0083,  0.3100, -0.0525, -0.0043,  0.2678, -0.0637,\n",
      "         -0.2509, -0.2087],\n",
      "        [-0.0945,  0.1659,  0.2146,  0.2467, -0.1220, -0.1729, -0.1007,  0.2897,\n",
      "         -0.2015, -0.0516],\n",
      "        [ 0.2321,  0.2716,  0.2748,  0.2159, -0.2179, -0.1416,  0.1271,  0.2732,\n",
      "          0.0048, -0.0830]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0367,  0.0745, -0.0357], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "nb_epochs = 1000\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    y_pred = model(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss)\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
